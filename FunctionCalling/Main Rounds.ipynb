{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdbce7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import random\n",
    "from langchain.llms import OpenAI\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-1106\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3209c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_content(content):\n",
    "    \"\"\"Parse the content string to extract parameters.\"\"\"\n",
    "    try:\n",
    "        # Assuming the content is in JSON format\n",
    "        params = json.loads(content)\n",
    "        return params\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error parsing content.\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d194c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_firstRound_info(AcneType, duration, check_oily_skin, check_itchiness_or_pain):\n",
    "#     AcneType=args.get(\"AcneType\")\n",
    "#     duration=args.get(\"duration\")\n",
    "#     check_oily_skin=args.get(\"check_oily_skin\")\n",
    "#     check_itchiness_or_pain=args.get(\"check_itchiness_or_pain\")\n",
    "#     content =message.get(\"content\",\"{}\")\n",
    "#     params=parse_content(content)\n",
    "#     AcneType = params.get(\"AcneType\")\n",
    "#     duration = params.get(\"duration\")\n",
    "#     check_oily_skin = params.get(\"check_oily_skin\")\n",
    "#     check_itchiness_or_pain = params.get(\"check_itchiness_or_pain\")\n",
    "\n",
    "    if AcneType is None:\n",
    "        AcneType = get_input(\"Enter AcneType (Acne, Acne_Scar, Both): \", str)\n",
    "\n",
    "    if duration is None:\n",
    "        duration = get_input(\"Enter the duration that the problem lasts: \", str)\n",
    "\n",
    "    if check_oily_skin is None:\n",
    "        check_oily_skin_input = get_input(\"Do you have oily skin? (yes/no): \", str)\n",
    "        check_oily_skin = check_oily_skin_input.strip().lower() == \"yes\"\n",
    "\n",
    "    if check_itchiness_or_pain is None:\n",
    "        check_itchiness_or_pain = get_input(\"Do you have itchiness or pain? (yes/no): \", str)\n",
    "        \n",
    "    firstRound_info = {\n",
    "        \"AcneType\": AcneType,\n",
    "        \"duration\": duration,\n",
    "        \"check_oily_skin\": check_oily_skin,\n",
    "        \"check_itchiness_or_pain\": check_itchiness_or_pain,\n",
    "    }\n",
    "    return json.dumps(firstRound_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517ee609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_firstRound_info(AcneType, duration, check_oily_skin, check_itchiness_or_pain)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_firstRound_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db06f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secondRound_info(pic, check_squeezing_acne, strategy):\n",
    "    secondRound_info = {\n",
    "        \"pic\": pic,\n",
    "        \"check_squeezing_acne\":check_squeezing_acne,\n",
    "        \"strategy\":strategy\n",
    "    }\n",
    "    return json.dumps(secondRound_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c937a9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_secondRound_info(pic, check_squeezing_acne, strategy)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_secondRound_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775ed3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI,VectorDBQA\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "def emb():\n",
    "    # 加载txt文件\n",
    "    loader = UnstructuredFileLoader('./qa_pairs.txt')\n",
    "    # 将数据转成 document 对象，每个文件会作为一个 document\n",
    "    documents = loader.load()\n",
    "\n",
    "    # 初始化加载器\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "    # 切割加载的 document\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # 初始化 openai 的 embeddings 对象\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "    # 将 document 通过 openai 的 embeddings 对象计算 embedding 向量信息并临时存入 Chroma 向量数据库，用于后续匹配查询\n",
    "    docsearch = Chroma.from_documents(split_docs, embeddings)\n",
    "\n",
    "    # 创建问答对象\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=OpenAI(), \n",
    "        chain_type=\"stuff\", \n",
    "        retriever=docsearch.as_retriever(),\n",
    "        return_source_documents=True) \n",
    "    # 进行问答\n",
    "    result = qa({\"query\": \"痘痘\"})\n",
    "\n",
    "    # print(result)\n",
    "    retrieved_result = result['result']\n",
    "#     print(retrieved_result)\n",
    "    return retrieved_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddce3fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 多长时间了呢，是不是反复长'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01cd0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_conversation():\n",
    "#     # Step 1: send the conversation and available functions to the model\n",
    "#     messages = [{\"role\": \"user\", \"content\": \"Can you recommend a type of Skin Care product?\"}]\n",
    "#     tools = [\n",
    "#         {\n",
    "#             \"type\": \"function\",\n",
    "#             \"function\": {\n",
    "#                 \"name\": \"get_firstRound_info\",\n",
    "#                 \"description\": \"Get the first round info\",  # 获得第一轮诊断所需要的信息\n",
    "#                 \"parameters\": {\n",
    "#                     \"type\": \"object\",\n",
    "#                     \"properties\": {\n",
    "#                         \"AcneType\": {\n",
    "#                             \"type\": \"string\",\n",
    "#                             \"enum\": [\"Acne\", \"Acne_Scar\", \"Both\"],\n",
    "#                             \"description\": \"The problem user want to solve, e.g. Acne\",\n",
    "#                         },\n",
    "#                         \"duration\": {\n",
    "#                             \"type\": \"string\",\n",
    "#                             \"description\": \"The duration that the problem lasts\"\n",
    "#                         },\n",
    "#                         \"check_oily_skin\": {\n",
    "#                             \"type\": \"boolean\",\n",
    "#                             \"description\": \"Check user has a oily skin or not\",\n",
    "#                         },\n",
    "#                         \"check_itchiness_or_pain\": {\n",
    "#                             \"type\": \"string\",\n",
    "#                             \"description\": \"Check if user have itchiness or pain\",\n",
    "#                         }\n",
    "#                     }\n",
    "\n",
    "#                 },\n",
    "#                 # \"required\": [\"location\", \"format\"],\n",
    "#                 \"required\": [\"AcneType\", \"duration\", \"check_oily_skin\", \"check_itchiness_or_pain\"],\n",
    "#             },\n",
    "\n",
    "#         },\n",
    "#         {\n",
    "#             \"type\": \"function\",\n",
    "#             \"function\": {\n",
    "#                 \"name\": \"get_secondRound_info\",\n",
    "#                 \"description\": \"Get the second round info, You should NEVER call this function before get_firstRound_info has been called in the conversation.\",  # 获取最终诊断信息\n",
    "#                 \"parameters\": {\n",
    "#                     \"type\": \"object\",\n",
    "#                     \"properties\": {\n",
    "#                         \"pic\": {\n",
    "#                             \"type\": \"string\",\n",
    "#                             \"description\": \"Pic with symptoms\",\n",
    "#                         },\n",
    "#                         \"check_squeezing_acne\": {\n",
    "#                             \"type\": \"boolean\",\n",
    "#                             \"description\": \"Check the useer squeeze acne or not.\",\n",
    "#                         },\n",
    "#                         \"strategy\": {\n",
    "#                             \"type\": \"boolean\",\n",
    "#                             \"description\": \"Check if user answered their skin care strategy\",\n",
    "#                         }\n",
    "#                     },\n",
    "#                     \"required\": [\"pic\", \"check_squeezing_acne\", \"strategy\"]\n",
    "#                 },\n",
    "#             }\n",
    "#         },\n",
    "#     ]\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-3.5-turbo-1106\",\n",
    "# #         model=\"gpt-4\",\n",
    "#         messages=messages,\n",
    "#         tools=tools,\n",
    "#         tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "#     )\n",
    "#     response_message = response.choices[0].message\n",
    "#     print(f\"response_message:\\n{response_message}\", end='\\n\\n')  # print the previous answer\n",
    "#     tool_calls = response_message.tool_calls\n",
    "#     # Step 2: check if the model wanted to call a function\n",
    "#     if tool_calls:\n",
    "#         # Step 3: call the function\n",
    "#         # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "#         available_functions = {\n",
    "#             \"get_firstRound_info\": get_firstRound_info,\n",
    "#             \"get_secondRound_info\": get_secondRound_info,\n",
    "#         }  # only one function in this example, but you can have multiple\n",
    "#         messages.append(response_message)  # extend conversation with assistant's reply\n",
    "#         # Step 4: send the info for each function call and function response to the model\n",
    "#         for tool_call in tool_calls:\n",
    "#             function_name = tool_call.function.name\n",
    "#             function_to_call = available_functions[function_name]\n",
    "#             function_args = json.loads(tool_call.function.arguments)\n",
    "#             function_response = function_to_call(\n",
    "# #                 location=function_args.get(\"location\"),\n",
    "# #                 unit=function_args.get(\"unit\"),\n",
    "#                 AcneType=function_args.get(\"AcneType\"),\n",
    "#                 duration=function_args.get(\"duration\"),\n",
    "#                 check_oily_skin=function_args.get(\"check_oily_skin\"),\n",
    "#                 check_itchiness_or_pain=function_args.get(\"check_itchiness_or_pain\"),\n",
    "# #                 pic=function_args.get(\"pic\"),\n",
    "# #                 check_squeezing_acne=function_args.get(\"check_squeezing_acne\"),\n",
    "# #                 strategy=function_args.get(\"strategy\")\n",
    "                \n",
    "#             )\n",
    "#             messages.append(\n",
    "#                 {\n",
    "#                     \"tool_call_id\": tool_call.id,\n",
    "#                     \"role\": \"tool\",\n",
    "#                     \"name\": function_name,\n",
    "#                     \"content\": emb(), # 把Embedding改过的话放在这\n",
    "#                 }\n",
    "#             )  # extend conversation with function response\n",
    "#         second_response = client.chat.completions.create( # here to use embedding? Need a test!\n",
    "#             model=\"gpt-3.5-turbo-1106\",\n",
    "# #             model=\"gpt-4\",\n",
    "#             messages=messages,\n",
    "# #             tools=tools,\n",
    "# #             model=\"text-embedding-ada-002\",\n",
    "# #             messages=messages,\n",
    "#         )  # get a new response from the model where it can see the function response\n",
    "#         print(f\"second_response:\\n{second_response}\", end='\\n\\n')\n",
    "#         return second_response\n",
    "\n",
    "\n",
    "# print(f\"run_conversation:\\n{run_conversation()}\", end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d40490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a9e3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "#     print(f\"json_data:{json_data}\")\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\":functions})\n",
    "#     print(\"JSON data being sent:\", json.dumps(json_data, indent=4))\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decaf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self):\n",
    "        self.conversation_history=[]\n",
    "    \n",
    "    def add_message(self,role,content):\n",
    "        message={\"role\":role,\"content\":content}\n",
    "        self.conversation_history.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0529edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_functions = [\n",
    "        {\n",
    "            \"name\": \"get_firstRound_info\",\n",
    "            \"description\": \"Use this function to Get basic information of user. Always check if each parameter is satisfied, and if not, ask in turn\",  # 获得第一轮诊断所需要的信息\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"AcneType\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"Acne\", \"Acne_Scar\", \"Both\"],\n",
    "                        \"description\": \"The problem user want to solve, e.g. Acne\",\n",
    "                    },\n",
    "                    \"duration\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The duration that the problem lasts\"\n",
    "                    },\n",
    "                    \"check_oily_skin\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Check user has a oily skin or not\",\n",
    "                    },\n",
    "                    \"check_itchiness_or_pain\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Check if user have itchiness or pain\",\n",
    "                    }\n",
    "                },\n",
    "                \n",
    "                \"required\": [\"AcneType\", \"duration\", \"check_oily_skin\", \"check_itchiness_or_pain\"],\n",
    "            },\n",
    "\n",
    "        },\n",
    "        {\n",
    "            \n",
    "            \"name\": \"get_secondRound_info\",\n",
    "            \"description\": \"Use this function right after 'get_firstRound_info' to get a more detailed information. You should NEVER call this function before 'get_firstRound_info' has been called in the conversation.\",  # 获取最终诊断信息\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"pic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Pic with symptoms\",\n",
    "                    },\n",
    "                    \"check_squeezing_acne\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Check the useer squeeze acne or not.\",\n",
    "                    },\n",
    "                    \"strategy\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Check if user answered their skin care strategy\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"pic\", \"check_squeezing_acne\", \"strategy\"]\n",
    "            },\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d67a5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion_with_function_execution(messages,functions=[None]):\n",
    "    response = chat_completion_request(messages, functions)\n",
    "#     print(f'response:{response}')\n",
    "    if response.status_code ==200:\n",
    "        try:\n",
    "            full_message = response.json()[\"choices\"][0]\n",
    "#             print(f\"full_message{full_message}\")\n",
    "            if full_message[\"finish_reason\"] == \"function_call\":\n",
    "                print(f\"Function generation requested, calling function\")\n",
    "                return call_main_round_function(messages, full_message)\n",
    "            else:\n",
    "                print(f\"Function not required, responding to user\")\n",
    "                return response.json()\n",
    "        except KeyError:\n",
    "            print(response.json())\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"API Request failed with status code: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "def call_main_round_function(messages, full_message):\n",
    "    if full_message[\"message\"][\"function_call\"][\"name\"] == \"get_firstRound_info\":\n",
    "        try:\n",
    "            parsed_output = json.loads(\n",
    "                full_message[\"message\"][\"function_call\"][\"arguments\"]\n",
    "            )\n",
    "            print(\"Getting First Round Info\")\n",
    "            \n",
    "            AcneType=parsed_output.get(\"AcneType\")\n",
    "            duration=parsed_output.get(\"duration\")\n",
    "            check_oily_skin = parsed_output.get(\"check_oily_skin\")\n",
    "            check_itchiness_or_pain = parsed_output.get(\"check_itchiness_or_pain\")\n",
    "            \n",
    "            results = get_firstRound_info(AcneType,duration,check_oily_skin,check_itchiness_or_pain)\n",
    "#             print(f'results:{results}')\n",
    "        except Exception as e:\n",
    "            print(parsed_output)\n",
    "            print(f\"Function execution failed\")\n",
    "            print(f\"Error message: {e}\")\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": full_message[\"message\"][\"function_call\"][\"name\"],\n",
    "                \"content\": str(results),\n",
    "            }\n",
    "        )\n",
    "        try:\n",
    "            print(\"Got first round info, getting second round info\") # 更改\n",
    "            response = chat_completion_request(messages)\n",
    "            print(f'response:{response.json}')\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            raise Exception(\"Function chat request failed\")\n",
    "\n",
    "    elif (\n",
    "        full_message[\"message\"][\"function_call\"][\"name\"] == \"get_secondRound_info\"\n",
    "    ):\n",
    "        parsed_output = json.loads(\n",
    "            full_message[\"message\"][\"function_call\"][\"arguments\"]\n",
    "        )\n",
    "        print(\"Getting second round info\")\n",
    "        summary = get_secondRound_info(parsed_output[\"query\"])\n",
    "        return summary\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Function does not exist and cannot be called\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3174bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iry_system_message=\"\"\"You are IRYGPT, a helpful assistant to guide user to purchase facial skin care products.Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.Answer in Chinese.\n",
    "Begin!\"\"\"\n",
    "iry_conversation= Conversation()\n",
    "iry_conversation.add_message(\"system\",iry_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5dd7bc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your message: 你好，我要找小希\n",
      "Function not required, responding to user\n",
      "你好，很高兴能帮助您。您有什么关于面部护理产品的需求吗？\n",
      "Enter your message: 痘痘\n",
      "Function generation requested, calling function\n",
      "Getting First Round Info\n",
      "Got first round info, getting second round info\n",
      "response:<bound method Response.json of <Response [200]>>\n",
      "了解了，您希望找到能缓解痘痘问题的产品。请问您想要试试清洁产品、护肤品还是治疗痘痘的产品呢？\n",
      "Enter your message: 痘痘\n",
      "Function not required, responding to user\n",
      "明白了，接下来我需要了解一些更详细的信息。您是否经常挤压痘痘？是否已经使用过其他护肤策略来对抗痘痘呢？\n",
      "Enter your message: 是的，没有\n",
      "Function generation requested, calling function\n",
      "Getting second round info\n",
      "{'id': 'chatcmpl-8ehKfGGHA0cqQmECsUZnSP2GlQUNa', 'object': 'chat.completion', 'created': 1704710381, 'model': 'gpt-3.5-turbo-1106', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '好的，非常感谢您的回答。请您稍等，我将为您找到适合解决痘痘问题的护肤产品。', 'function_call': {'name': 'get_secondRound_info', 'arguments': '{\"pic\":\"pic\",\"check_squeezing_acne\":true,\"strategy\":false}'}}, 'logprobs': None, 'finish_reason': 'function_call'}], 'usage': {'prompt_tokens': 549, 'completion_tokens': 76, 'total_tokens': 625}, 'system_fingerprint': 'fp_cbe4fa03fe'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m     chat_response\u001b[38;5;241m=\u001b[39mchat_completion_with_function_execution(\n\u001b[0;32m      5\u001b[0m         iry_conversation\u001b[38;5;241m.\u001b[39mconversation_history, functions\u001b[38;5;241m=\u001b[39mmain_functions\n\u001b[0;32m      6\u001b[0m     )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     print(chat_response)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     assistant_message \u001b[38;5;241m=\u001b[39m chat_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      9\u001b[0m     iry_conversation\u001b[38;5;241m.\u001b[39madd_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,assistant_message)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(assistant_message)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter your message: \")\n",
    "    iry_conversation.add_message(\"user\", user_input)\n",
    "    chat_response=chat_completion_with_function_execution(\n",
    "        iry_conversation.conversation_history, functions=main_functions\n",
    "    )\n",
    "#     print(chat_response)\n",
    "    assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    iry_conversation.add_message(\"assistant\",assistant_message)\n",
    "    print(assistant_message)\n",
    "# while True:\n",
    "#     # Get user input\n",
    "#     user_input = input(\"User: \")\n",
    "#     iry_conversation.add_message(\"user\", user_input)\n",
    "    \n",
    "\n",
    "#     # Process input through GPT chatbot\n",
    "#     chat_response = chat_completion_with_function_execution(\n",
    "#         iry_conversation.conversation_history, functions=main_functions\n",
    "#     )\n",
    "    \n",
    "#     # Check if a custom function needs to be called\n",
    "# #     if needs_custom_function(chat_response):\n",
    "# #         # Call custom function (like get_firstRound_info) and process\n",
    "# #         custom_function_response = call_custom_function(chat_response)\n",
    "# #         iry_conversation.add_message(\"assistant\", custom_function_response)\n",
    "# #     else:\n",
    "# #         # Normal chatbot response\n",
    "# #         assistant_message = extract_message_from_response(chat_response)\n",
    "# #         iry_conversation.add_message(\"assistant\", assistant_message)\n",
    "# #         print(\"Assistant:\", assistant_message)\n",
    "\n",
    "#     # Check for conversation end conditions, if any\n",
    "#     if conversation_should_end(user_input, assistant_message):\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093f722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
